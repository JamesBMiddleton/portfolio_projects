{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a K-Nearest Neighbours classifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The K-Nearest Neighbours (KNN) model provides a simple example of machine learning, in which unknown values can be classified using the known classifications of similar values.\n",
    "\n",
    "This notebook provides a step-by-step process of readying a dataset for input, building a KNN classifier and assessing it's performance without the use of sklearn's pre-built equivalents.\n",
    "\n",
    "__Theory__\n",
    "\n",
    "KNN relies on the fact that items in the same category tend to have similar characteristics, so by determining which items of known category have the most similar characteristics to an unknown item, its category can be predicted.\n",
    "\n",
    "Distance measures are used to determine the 'closeness' of items, in which the differences between each of their characteristics are used to calculate a single measure of distance. While many different distance measures exist for different situations, this example will use _Euclidean distance_, the formula for which is as follows:\n",
    "\n",
    "$D(a,b) = \\sqrt{\\sum_{i=1}^{n}(b_{i}-a_{i})^{2}}$\n",
    "\n",
    "In plain english; the distance between item a and item b is equal to the square root of the sum of the squared differences between each item's characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dataset\n",
    "\n",
    "The input data for a KNN classifier includes two parts:\n",
    "- A categorical target/label variable which we would like to predict using the model\n",
    "- Multiple feature variables, the values of which vary between categories of the target variable.\n",
    "\n",
    "This seaborn sample dataset which we will use for our model includes 4 feature variables describing the dimensions of iris petals and sepals, as well a target variable specifying the species.\n",
    "\n",
    "Before the dataset can be used, the all variables must be converted to a numeric format to allow calculations to be performed across the whole dataset. Therefore, our three iris species must be converted to 0, 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "print(iris.shape)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f68cabb93bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species_numeric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "iris.species = pd.Categorical(iris.species)\n",
    "iris['species_numeric'] = iris.species.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor', 'virginica']\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(list(iris.species.unique()))\n",
    "print(iris.species_numeric.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = iris.iloc[:, 0:4].to_numpy()\n",
    "iris_labels = iris.species_numeric.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Distance measures treat each feature variable equally when calculating the distance between two values. Therefore a mismatch in scale would result in the differences in one feature variable having a much larger impact on distance than another.\n",
    "\n",
    "Min-max normalising the data solves this problem by converting all feature variables to the same scale from 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(data):\n",
    "    #iterating through each column, min-max normalising all values\n",
    "    for column in range(data.shape[1]):\n",
    "        data[:,column] = (data[:,column] - data[:,column].min()) / (data[:,column].max() - data[:,column].min())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "In order to assess the performance of the model, we need to partition our data into training and testing groups. \n",
    "\n",
    "If we tested and tweaked the model using the same data used to build it, there is a much greater chance of overfitting, in which the model performance very well on the current data, but poorly on new data it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, labels):\n",
    "    \n",
    "    #creating a randomly ordered range the length of the data\n",
    "    indices = list(range(len(data)))\n",
    "    random.shuffle(indices)\n",
    "    split = int(len(data) * 0.75)\n",
    "    \n",
    "    #selecting the first 75% of the randomly ordered data\n",
    "    train_data = data[indices[:split]]\n",
    "    train_labels = labels[indices[:split]]\n",
    "    \n",
    "    #selecting the remaining 25%\n",
    "    test_data = data[indices[split:]]\n",
    "    test_labels = labels[indices[split:]]\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest classifier\n",
    "\n",
    "The KNN classifier class has been built as a simplified version sklearn's KNN classifier.\n",
    "\n",
    "Step-by-step it functions as follows:\n",
    "1. The 'fit' method is used to create instance variables for the characteristics (train_data) and category (train_labels) of items in our training group. \n",
    "\n",
    "\n",
    "2. The 'predict' method takes in the characteristics of items in our testing group (test_data) and predicts their category by finding the most common category of the 'K' closest items in our training group. The 'K' number adjusts how many neighbouring items are used to make a classification.\n",
    "\n",
    "\n",
    "3. The 'score' method calls upon the 'predict' method to predict the categories of every item in the testing group, and then compares the predictions to the actual categories of the testing group to calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_nearest_classifier():\n",
    "    class\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    def predict(self, test_data, k):\n",
    "        \n",
    "        #finds the euclidean distance between any two datapoints using each of their features\n",
    "        def euclidean_distance(datapoint_1, datapoint_2):\n",
    "            total = 0\n",
    "            for x in range(len(datapoint_1)):\n",
    "                total += (datapoint_1[x] - datapoint_2[x])**2\n",
    "            return total ** 0.5\n",
    "        \n",
    "        predictions = []\n",
    "        for test_datapoint in range(len(test_data)):\n",
    "            \n",
    "            #finds the distance between an unknown datapoint and all datapoints in the labelled training data\n",
    "            neighbours = []\n",
    "            for train_datapoint in range(len(self.train_data)):\n",
    "                distance = euclidean_distance(test_data[test_datapoint], self.train_data[train_datapoint])\n",
    "                label = train_labels[train_datapoint]\n",
    "                neighbours.append([distance, label])\n",
    "\n",
    "            #finds the 'k' closest training datapoints to the unknown datapoint\n",
    "            neighbours.sort()\n",
    "            neighbours = neighbours[0:k]\n",
    "\n",
    "            #creating an array of zeros, the indices of which represent each category in the dataset\n",
    "            num_categories = len(set(train_labels))\n",
    "            count = np.zeros(num_categories)\n",
    "\n",
    "            #iterating through each neighbour's category, adding 1 to the corresponding indice, returning the most common\n",
    "            for neighbour in neighbours:\n",
    "                count[neighbour[1]] += 1\n",
    "\n",
    "            predictions.append(count.argmax())\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def score(self, test_data, test_labels, k):\n",
    "        \n",
    "        predictions = self.predict(test_data, k)\n",
    "        \n",
    "        num_correct = 0.\n",
    "        for x in range(len(predictions)):\n",
    "            if predictions[x] == test_labels[x]:\n",
    "                num_correct += 1\n",
    "        return round(num_correct / len(test_labels), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing  / assessing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = normalise(iris_data)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(iris_data, iris_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = K_nearest_classifier()\n",
    "classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_data, test_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted categories:\n",
      "[2, 0, 1, 2, 1, 1, 0, 1, 0, 2, 2, 0, 1, 2, 0, 0, 2, 1, 0, 1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 2, 0]\n",
      "True categories:\n",
      "[2, 0, 1, 2, 1, 1, 0, 1, 0, 2, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Predicted categories:')\n",
    "print(list(classifier.predict(test_data, 5))) \n",
    "print('True categories:')\n",
    "print(list(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
